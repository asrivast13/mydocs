{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "975a9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import warnings\n",
    "import logging\n",
    "from typing import Optional, Callable\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    Wav2Vec2Processor, \n",
    "    AutoModelForCTC\n",
    ")\n",
    "from huggingsound.utils import get_chunks, get_waveforms, get_dataset_from_dict_list\n",
    "from huggingsound.token_set import TokenSet\n",
    "from huggingsound.normalizer import DefaultTextNormalizer\n",
    "from huggingsound.speech_recognition.decoder import Decoder, GreedyDecoder\n",
    "\n",
    "import collections\n",
    "import contextlib\n",
    "import wave\n",
    "\n",
    "from traceback import print_tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "705676ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wave(path):\n",
    "    \"\"\"Reads a .wav file.\n",
    "    Takes the path, and returns (PCM audio data, sample rate).\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
    "        num_channels = wf.getnchannels()\n",
    "        assert num_channels == 1\n",
    "        sample_width = wf.getsampwidth()\n",
    "        assert sample_width == 2\n",
    "        sample_rate = wf.getframerate()\n",
    "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
    "        pcm_data = wf.readframes(wf.getnframes())\n",
    "        return pcm_data, sample_rate\n",
    "\n",
    "def write_wave(path, audio, sample_rate):\n",
    "    \"\"\"Writes a .wav file.\n",
    "    Takes path, PCM audio data, and sample rate.\n",
    "    \"\"\"\n",
    "    with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio)\n",
    "\n",
    "class Frame(object):\n",
    "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
    "    def __init__(self, bytes, timestamp, duration, is_speech = True):\n",
    "        self.bytes = bytes\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration\n",
    "        self.isSpeech = is_speech\n",
    "\n",
    "def __frame_generator_old(frame_duration_ms, audio, sample_rate, vad=None):\n",
    "    \"\"\"Generates audio frames from PCM audio data.\n",
    "    Takes the desired frame duration in milliseconds, the PCM data, and\n",
    "    the sample rate.\n",
    "    Yields Frames of the requested duration.\n",
    "    \"\"\"\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    duration = (float(n) / sample_rate) / 2.0\n",
    "    while offset + n < len(audio):\n",
    "        is_speech = vad.is_speech(audio[offset:offset + n], sample_rate) if vad is not None else False\n",
    "        yield Frame(audio[offset:offset + n], timestamp, duration, is_speech)\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "        \n",
    "class Utterance(object):\n",
    "    \"\"\"Represents an utterance of speech audio data.\"\"\"\n",
    "    def __init__(self, audio, timestamp, duration, bytes):\n",
    "        self.audio = audio\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration\n",
    "        self.bytes=bytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0201596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webrtcvad\n",
    "import numpy as np\n",
    "class AudioSegmenter(object):\n",
    "    \"\"\"Represents the WebRTC based Audio Segmentation tool\"\"\"\n",
    "    def __init__(self, \n",
    "                 vadAggressiveness=2, \n",
    "                 frameDurationMs=30, \n",
    "                 numFramesInWindow=100, \n",
    "                 samplingRate=16000, \n",
    "                 numBytesPerSample=2):\n",
    "        assert numBytesPerSample == 2  ## for now although the algo should work for byte encodings\n",
    "        self.vad = webrtcvad.Vad(vadAggressiveness)\n",
    "        self.sample_rate = samplingRate\n",
    "        self.frame_duration_ms = frameDurationMs\n",
    "        self.num_frames_in_window = numFramesInWindow\n",
    "        self.SCALE_FACTOR = 1./float(1 << ((8 * numBytesPerSample)-1))\n",
    "        self.num_bytes_per_sample = numBytesPerSample\n",
    "        \n",
    "    def frame_generator(self, audio):\n",
    "        \"\"\"Generates audio frames from PCM audio data.\n",
    "        Takes the desired frame duration in milliseconds, the PCM data, and\n",
    "        the sample rate.\n",
    "        Yields Frames of the requested duration.\n",
    "        \"\"\"\n",
    "        n = int(self.sample_rate * (self.frame_duration_ms / 1000.0) * 2)\n",
    "        offset = 0\n",
    "        timestamp = 0.0\n",
    "        duration = (float(n) / self.sample_rate) / 2.0\n",
    "        while offset + n < len(audio):\n",
    "            is_speech = self.vad.is_speech(audio[offset:offset + n], self.sample_rate)\n",
    "            yield Frame(audio[offset:offset + n], timestamp, duration, is_speech)\n",
    "            timestamp += duration\n",
    "            offset += n\n",
    "        \n",
    "    def vad_collector(self, frames, triggerToggleFactor=0.9, utteranceRunoffDuration=5, minSilenceAtEnds=0.06, verbosity=0):\n",
    "        \"\"\"Filters out non-voiced audio frames.\n",
    "        Given a webrtcvad.Vad and a source of audio frames, yields only\n",
    "        the voiced audio.\n",
    "        Uses a padded, sliding window algorithm over the audio frames.\n",
    "        When more than (triggerToggleFactor)X% (default X=90) of the frames in the window are voiced (as\n",
    "        reported by the VAD), the collector triggers and begins yielding\n",
    "        audio frames. Then the collector waits until X% of the frames in\n",
    "        the window are unvoiced to detrigger.\n",
    "        The window is padded at the front and back to provide a small\n",
    "        amount of silence or the beginnings/endings of speech around the\n",
    "        voiced frames.\n",
    "        Arguments:\n",
    "        sample_rate - The audio sample rate, in Hz.\n",
    "        frame_duration_ms - The frame duration in milliseconds.\n",
    "        padding_duration_ms - The amount to pad the window, in milliseconds.\n",
    "        vad - An instance of webrtcvad.Vad.\n",
    "        frames - a source of audio frames (sequence or generator).\n",
    "        Returns: A generator that yields PCM audio data.\n",
    "        \"\"\"\n",
    "        frame_duration_ms = self.frame_duration_ms\n",
    "        num_padding_frames = self.num_frames_in_window\n",
    "        sample_rate = self.sample_rate\n",
    "        min_silence_frames_at_end = int(minSilenceAtEnds * 1000 / frame_duration_ms)\n",
    "        if verbosity>2: \n",
    "            print('Min Silence Frames at End: %d' % min_silence_frames_at_end)\n",
    "        \n",
    "        # We use a deque for our sliding window/ring buffer.\n",
    "        ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "        # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
    "        # NOTTRIGGERED state.\n",
    "        triggered = False\n",
    "        start_time = -1\n",
    "        end_time = -1\n",
    "\n",
    "        ## smoothing on the frames\n",
    "        numFrames = len(frames)\n",
    "        for index, frame in enumerate(frames):\n",
    "            if(index > 0) and (index < (numFrames-1)):\n",
    "                if((frames[index].isSpeech != frames[index-1].isSpeech) and (frames[index-1].isSpeech == frames[index+1].isSpeech)):\n",
    "                    frames[index].isSpeech = frames[index-1].isSpeech\n",
    "\n",
    "        voiced_frames = []\n",
    "        segid = 1\n",
    "        num_silence_frames_at_end = 0\n",
    "        for frame in frames:\n",
    "            is_speech = frame.isSpeech\n",
    "\n",
    "            if verbosity > 3:\n",
    "                sys.stdout.write('1' if is_speech else '0')\n",
    "                sys.stdout.write(' %.2f\\n' % frame.timestamp)\n",
    "            if not triggered:\n",
    "                ring_buffer.append((frame, is_speech))\n",
    "                num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "                # If we're NOTTRIGGERED and more than 90% of the frames in\n",
    "                # the ring buffer are voiced frames, then enter the\n",
    "                # TRIGGERED state.\n",
    "                if num_voiced > triggerToggleFactor * ring_buffer.maxlen:\n",
    "                    triggered = True\n",
    "                    if verbosity > 3:\n",
    "                        sys.stdout.write('+(%s)\\n' % (ring_buffer[0][0].timestamp,))\n",
    "                    start_time = ring_buffer[0][0].timestamp\n",
    "                    # We want to yield all the audio we see from now until\n",
    "                    # we are NOTTRIGGERED, but we have to start with the\n",
    "                    # audio that's already in the ring buffer.\n",
    "                    for f, s in ring_buffer:\n",
    "                        voiced_frames.append(f)\n",
    "                    ring_buffer.clear()\n",
    "                    index = len(voiced_frames)-1\n",
    "                    while(index>=0):\n",
    "                        if(voiced_frames[index].isSpeech):\n",
    "                            break\n",
    "                        else:\n",
    "                            num_silence_frames_at_end += 1\n",
    "\n",
    "            else:\n",
    "                # We're in the TRIGGERED state, so collect the audio data\n",
    "                # and add it to the ring buffer.\n",
    "                voiced_frames.append(frame)\n",
    "                ring_buffer.append((frame, is_speech))\n",
    "                num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "                if not is_speech:\n",
    "                    num_silence_frames_at_end += 1\n",
    "                end_time = frame.timestamp + frame.duration\n",
    "                # If more than 90% of the frames in the ring buffer are\n",
    "                # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
    "                # audio we've collected.\n",
    "                if ((num_unvoiced > (triggerToggleFactor * ring_buffer.maxlen)) or \n",
    "                (((end_time - start_time) > utteranceRunoffDuration) and (num_silence_frames_at_end >= min_silence_frames_at_end))):\n",
    "                    if verbosity > 3:\n",
    "                        sys.stdout.write('-(%s)\\n' % (frame.timestamp + frame.duration))\n",
    "                    end_time = frame.timestamp + frame.duration\n",
    "                    #start_time -= minSilenceAtEnds if start_time >= minSilenceAtEnds else 0.0\n",
    "                    triggered = False\n",
    "                    databytes = b''.join([f.bytes for f in voiced_frames])\n",
    "                    audiosamples = np.frombuffer(databytes, dtype=np.int16).astype(np.float32)\n",
    "                    audiosamples *= self.SCALE_FACTOR\n",
    "                    if verbosity > 1:\n",
    "                        print('Segment %d: start=%.2f end=%.2f bytes=%d duration=%.2f\\n' % (segid, start_time, end_time, len(databytes), len(audiosamples)/sample_rate))\n",
    "                    segid += 1\n",
    "                    #databytes = None\n",
    "                    yield(Utterance(audiosamples, start_time, (end_time - start_time), databytes))\n",
    "                    start_time = -1\n",
    "                    end_time = -1\n",
    "                    ring_buffer.clear()\n",
    "                    voiced_frames = []\n",
    "                    num_silence_frames_at_end = 0\n",
    "        if verbosity > 3:\n",
    "            if triggered:\n",
    "                sys.stdout.write('-(%s)\\n' % (frame.timestamp + frame.duration))\n",
    "            sys.stdout.write('\\n')\n",
    "        # If we have any leftover voiced audio when we run out of input,\n",
    "        # yield it.\n",
    "        end_time = frame.timestamp + frame.duration\n",
    "        if voiced_frames:\n",
    "            databytes = b''.join([f.bytes for f in voiced_frames])\n",
    "            audiosamples = np.frombuffer(databytes, dtype=np.int16).astype(np.float32)\n",
    "            audiosamples *= self.SCALE_FACTOR\n",
    "            if verbosity > 1:\n",
    "                print('Segment %d: start=%.2f end=%.2f bytes=%d duration=%.2f\\n' % (segid, start_time, end_time, len(databytes), len(audiosamples)/sample_rate))\n",
    "            #databytes = None\n",
    "            yield(Utterance(audiosamples, start_time, (end_time - start_time), databytes))\n",
    "\n",
    "    def process(self, audio, triggerToggleFactor=0.9, utteranceRunoffDuration=5, minSilenceAtEnds=0.06):\n",
    "        frames = self.frame_generator(audio)\n",
    "        frames = list(frames)\n",
    "        \n",
    "        totalAudioDuration = len(audio) / (self.sample_rate * self.num_bytes_per_sample)\n",
    "        segmentsList = []\n",
    "        totalSpeechDuration = 0.0\n",
    "        totalNumSegments = 0\n",
    "        maxDuration = 0.0\n",
    "        speech_segments = self.vad_collector(frames, triggerToggleFactor, utteranceRunoffDuration, minSilenceAtEnds)\n",
    "        for segment in speech_segments:\n",
    "            if segment.duration > maxDuration:\n",
    "                maxDuration = segment.duration\n",
    "            totalSpeechDuration += segment.duration\n",
    "            totalNumSegments += 1\n",
    "            segmentsList.append(segment)\n",
    "        \n",
    "        print('Segmenter found total of %d segments with duration %.2fsecs from audio of duration %.2fsecs with max=%.2f -- compression factor: %.2f%%\\n' \n",
    "                  % (totalNumSegments, totalSpeechDuration, totalAudioDuration, maxDuration, (100.0*totalSpeechDuration/totalAudioDuration)))\n",
    "        return segmentsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4532879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "class SpeechRecognitionModel2():\n",
    "    \"\"\"\n",
    "    Speech Recognition Model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_path : str\n",
    "        The path to the model or the model identifier from huggingface.co/models.\n",
    "    \n",
    "    device: Optional[str] = \"cpu\"\n",
    "        Device to use for inference/evaluation/training, default is \"cpu\". If you want to use a GPU for that, \n",
    "        you'll probably need to specify the device as \"cuda\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_path: str, device: Optional[str] = \"cpu\"):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.device = device\n",
    "        \n",
    "        logger.info(\"Loading model...\")\n",
    "        self._load_model()\n",
    "\n",
    "    @property\n",
    "    def is_finetuned(self):\n",
    "        return self.processor is not None\n",
    "\n",
    "    def _load_model(self):\n",
    "\n",
    "        self.model = AutoModelForCTC.from_pretrained(self.model_path)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        try:\n",
    "            self.processor = Wav2Vec2Processor.from_pretrained(self.model_path)\n",
    "            self.token_set = TokenSet.from_processor(self.processor)\n",
    "        except Exception:\n",
    "            logger.warning(\"Not fine-tuned model! You'll need to fine-tune it before use this model for audio transcription\")\n",
    "            self.processor = None\n",
    "            self.token_set = None\n",
    "\n",
    "    def transcribeFiles(self, paths: list[str], batch_size: Optional[int] = 1, decoder: Optional[Decoder] = None) -> list[dict]:\n",
    "        \"\"\" \n",
    "        Transcribe audio files.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "            paths: list[str]\n",
    "                List of paths to audio files to transcribe\n",
    "\n",
    "            batch_size: Optional[int] = 1\n",
    "                Batch size to use for inference\n",
    "\n",
    "            decoder: Optional[Decoder] = None\n",
    "                Decoder to use for transcription. If you don't specify this, the engine will use the GreedyDecoder.\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "            list[dict]:\n",
    "                A list of dictionaries containing the transcription for each audio file:\n",
    "\n",
    "                [{\n",
    "                    \"transcription\": str,\n",
    "                    \"start_timesteps\": list[int],\n",
    "                    \"end_timesteps\": list[int],\n",
    "                    \"probabilities\": list[float]\n",
    "                }, ...]\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.is_finetuned:\n",
    "            raise ValueError(\"Not fine-tuned model! Please, fine-tune the model first.\")\n",
    "        \n",
    "        if decoder is None:\n",
    "            decoder = GreedyDecoder(self.token_set)\n",
    "\n",
    "        sampling_rate = self.processor.feature_extractor.sampling_rate\n",
    "        result = []\n",
    "\n",
    "        for paths_batch in tqdm(list(get_chunks(paths, batch_size))):\n",
    "\n",
    "            waveforms = get_waveforms(paths_batch, sampling_rate)\n",
    "\n",
    "            inputs = self.processor(waveforms, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True, do_normalize=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(inputs.input_values.to(self.device), attention_mask=inputs.attention_mask.to(self.device)).logits\n",
    "\n",
    "            result += decoder(logits)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def transcribeAudio(self, utterances: list[Utterance], batch_size: Optional[int] = 1, decoder: Optional[Decoder] = None) -> list[dict]:\n",
    "        \"\"\" \n",
    "        Transcribe audio files.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "            paths: list[Utterance]\n",
    "                List of audio utterances to transcribe\n",
    "\n",
    "            batch_size: Optional[int] = 1\n",
    "                Batch size to use for inference\n",
    "\n",
    "            decoder: Optional[Decoder] = None\n",
    "                Decoder to use for transcription. If you don't specify this, the engine will use the GreedyDecoder.\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "            list[dict]:\n",
    "                A list of dictionaries containing the transcription for each audio file:\n",
    "\n",
    "                [{\n",
    "                    \"transcription\": str,\n",
    "                    \"start_timesteps\": list[int],\n",
    "                    \"end_timesteps\": list[int],\n",
    "                    \"probabilities\": list[float]\n",
    "                }, ...]\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.is_finetuned:\n",
    "            raise ValueError(\"Not fine-tuned model! Please, fine-tune the model first.\")\n",
    "\n",
    "        if decoder is None:\n",
    "            decoder = GreedyDecoder(self.token_set)\n",
    "\n",
    "        sampling_rate = self.processor.feature_extractor.sampling_rate\n",
    "        result = []\n",
    "\n",
    "        for utts_batch in tqdm(list(get_chunks(utterances, batch_size))):\n",
    "\n",
    "            #waveforms = get_waveforms(paths_batch, sampling_rate)\n",
    "            waveforms = []\n",
    "            for utt in utts_batch:\n",
    "                waveforms.append(utt.audio)\n",
    "\n",
    "            inputs = self.processor(waveforms, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True, do_normalize=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(inputs.input_values.to(self.device), attention_mask=inputs.attention_mask.to(self.device)).logits\n",
    "\n",
    "            batchResults = decoder(logits)\n",
    "            for index, br in enumerate(batchResults):\n",
    "                br['utterance_start']    = '%.2f' % utts_batch[index].timestamp\n",
    "                br['utterance_duration'] = '%.2f' % utts_batch[index].duration\n",
    "                br['tokens'] = self.convertToCTM(br)\n",
    "            result += batchResults\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def convertToCTM(self, utterance: dict, extrapolate: Optional[bool] = False) -> dict:\n",
    "        transcript  = utterance[\"transcription\"]\n",
    "        uttstart    = float(utterance['utterance_start'])\n",
    "        duration    = float(utterance['utterance_duration'])\n",
    "        char_starts = utterance[\"start_timestamps\"]\n",
    "        char_ends   = utterance[\"end_timestamps\"]\n",
    "        tokens = []\n",
    "\n",
    "        if((len(transcript) != len(char_starts)) \n",
    "           or (len(char_starts) != len(char_ends)) \n",
    "           or (char_ends[-1] > (duration * 1000))):\n",
    "            extrapolate = True\n",
    "\n",
    "        if(extrapolate):\n",
    "            words = transcript.split()\n",
    "            numChars = len(transcript)\n",
    "            start = uttstart\n",
    "            start += 0.1\n",
    "            dur = 0.0\n",
    "            for word in words:\n",
    "                dur = duration * len(word) / numChars\n",
    "                #ctmline = \"%s 1 %.2f %.2f %s\" % (sessionId, start, dur, word)\n",
    "                ctm = {\"baseform\": word, \"start\": start, \"duration\": dur}\n",
    "                start += dur\n",
    "                tokens.append(ctm)\n",
    "        else:\n",
    "            word = \"\"\n",
    "            start = -1\n",
    "            dur = 0.0\n",
    "            for index, char in enumerate(transcript):\n",
    "                if(char == \" \"):\n",
    "                    if(len(word)>0):\n",
    "                        #ctmline = \"%s 1 %.2f %.2f %s\" % (sessionId, (uttstart + start/1000), dur/1000, word)\n",
    "                        wst = (uttstart + start/1000)\n",
    "                        wd  = dur/1000\n",
    "                        ctm = {\"baseform\": word, \"start\": wst, \"duration\": wd}\n",
    "                        tokens.append(ctm)\n",
    "                        word = \"\"\n",
    "                        start = -1\n",
    "                        dur = 0.0\n",
    "                else:\n",
    "                    if(len(word)==0):\n",
    "                        start = char_starts[index]\n",
    "                    word += char\n",
    "                    dur = char_ends[index] - start\n",
    "\n",
    "            if(len(word)>0):\n",
    "                #ctmline = \"%s 1 %.2f %.2f %s\" % (sessionId, (uttstart + start/1000), dur/1000, word)\n",
    "                wst = (uttstart + start/1000)\n",
    "                wd  = dur/1000\n",
    "                ctm = {\"baseform\": word, \"start\": wst, \"duration\": wd}\n",
    "                tokens.append(ctm)\n",
    "                word = \"\"\n",
    "                start = -1\n",
    "                dur = 0.0\n",
    "\n",
    "        return tokens\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf94dcbc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0001_S003_0_G0001_G0002 16000 1215.53 /home/asrivast/d/Data/Speech/MagicData/Spanish_Conversational_Speech_Test_Corpus/WAV/A0001_S003_0_G0001_G0002.wav\n",
      "\n",
      "Segmenter found total of 232 segments with duration 1171.98secs from audio of duration 1215.53secs with max=13.38 -- compression factor: 96.42%\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ecde343",
   "metadata": {},
   "source": [
    "from traceback import print_tb\n",
    "import torch\n",
    "import os.path\n",
    "import argparse\n",
    "#from huggingsound import SpeechRecognitionModel, KenshoLMDecoder\n",
    "\n",
    "device = \"cuda\" if (torch.cuda.is_available()) else \"cpu\"\n",
    "print('device = %s' % device)\n",
    "#device='cpu'\n",
    "#SttModelFolder = \"/Users/asrivast/Models/wav2vec2-large-xlsr-53-english/\"\n",
    "SttModelFolder = \"/home/asrivast/Models/wav2vec2-large-xlsr-53-spanish/\"\n",
    "model = SpeechRecognitionModel2(SttModelFolder, device=device)\n",
    "print(model.processor.feature_extractor.sampling_rate)\n",
    "useLM = True\n",
    "decoder = None\n",
    "if useLM == True:\n",
    "    from huggingsound import KenshoLMDecoder\n",
    "    LmModelFolder = SttModelFolder + \"/language_model/\"\n",
    "    lm_path = LmModelFolder + \"lm.binary\"\n",
    "    unigrams_path = LmModelFolder + \"unigrams.txt\"\n",
    "    decoder = KenshoLMDecoder(model.token_set, lm_path=lm_path, unigrams_path=unigrams_path, alpha=2, beta=1, beam_width=100)\n",
    "    print(\"Finished loading Language Model\")\n",
    "\n",
    "transcripts = model.transcribeAudio(segments, 1, decoder)\n",
    "#print(transcripts)\n",
    "\n",
    "for transcript in transcripts:\n",
    "    print('%s (%s-%s)\\n' % (transcript['transcription'], transcript['utterance_start'], transcript['utterance_duration']))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78f0d803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Audio Segmenter with aggressiveness=3 frame length=30msec window size=20frames and sample rate=16000\n",
      "\n",
      "device = cuda\n",
      "Loading speech recognition model from folder /home/asrivast/Models/wav2vec2-large-xlsr-53-spanish/\n",
      "\n",
      "04/20/2022 07:33:20 - INFO - __main__ - Loading model...\n",
      "A0001_S003_0_G0001_G0002 16000 1215.53 /home/asrivast/d/Data/Speech/MagicData/Spanish_Conversational_Speech_Test_Corpus/WAV/A0001_S003_0_G0001_G0002.wav\n",
      "\n",
      "Segmenter found total of 232 segments with duration 1171.98secs from audio of duration 1215.53secs with max=13.38 -- compression factor: 96.42%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 232/232 [00:17<00:00, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "voys date a coleccion for beiteene magic data (4.71-3.78)\n",
      "\n",
      "\n",
      "boys data collection forbay-jin magic data (8.73-3.45)\n",
      "\n",
      "\n",
      "pues la verdad es que ahora mismo (12.75-2.94)\n",
      "\n",
      "\n",
      "eh todos los productos digitales que hay a mi me parece increíble  porque (15.69-5.01)\n",
      "\n",
      "\n",
      "no hace tanto tiempo no teníamos ni la cuarta parte de (20.70-4.23)\n",
      "\n",
      "\n",
      "de todo lo que tenemos hoy (24.93-1.74)\n",
      "\n",
      "\n",
      "antiguamente un telefono era para hablar el  telefono fijo que estaba en la entrada de (27.60-5.01)\n",
      "\n",
      "\n",
      "desde casa o en la sala y para conversaciones (32.61-5.01)\n",
      "\n",
      "\n",
      "breves progamas como tes playaras con tus amigos ya cuelga quevo ven ena factura no (37.80-5.01)\n",
      "\n",
      "\n",
      "creíble (42.81-1.05)\n",
      "\n",
      "\n",
      "y ahora granadavamos todos un mundo gol telephono móvil a todos lados que sales de casa y teoridos al telefonio vás corriendo a caso a travez a buscarlo como si se tuviera olvidado (44.25-8.79)\n",
      "\n",
      "\n",
      "medio cerebro sí  pero mira por ejemplo a mio parece super práctico  porque antes (53.31-5.01)\n",
      "\n",
      "\n",
      "por ejemplo sólo podíamos sacar fotografías si llevabas la cámara si tenías el carrete (58.32-5.01)\n",
      "\n",
      "\n",
      "es verdad que luego salieron las cámaras digitales y vas con la tarjetita ya era mucho más cómodo porque (63.33-5.37)\n",
      "\n",
      "\n",
      "de las descargas en el ordenador y ademas no pero ahora quien tiene un móvil tiene una cámara (68.82-5.01)\n",
      "\n",
      "\n",
      "fotográfica y eso la verdad es que te sirve para un montón de cosas para guardar (73.83-5.01)\n",
      "\n",
      "\n",
      "un montón de recuerdos que antes no podríamos  la verdades que me parece un gran adelanto (78.84-4.80)\n",
      "\n",
      "\n",
      "siambre está claro (83.64-1.83)\n",
      "\n",
      "\n",
      "los adelanto es ya no solo por la cámara esque ahora en un telefono móvil de vas (85.47-4.77)\n",
      "\n",
      "\n",
      "un arsenal de herramientas desde el jeps que antiguamente tebasal cualquier sitio que no conocierase y tenías qe estar preguntando (90.24-6.78)\n",
      "\n",
      "\n",
      "a el vecino que te encontrabas por el camino deoyga disculpe cómo hago pa llegar (97.77-5.01)\n",
      "\n",
      "\n",
      "a tal sitio donde queda esto ahora metes la dirección en el telefono movil y te lleva hasta la puerta (102.90-5.01)\n",
      "\n",
      "\n",
      "in mayor complicación a no ser que te desvíe  algún sitio (107.91-5.01)\n",
      "\n",
      "\n",
      "rror de cabeza me de un pantano no pero no son las cosas más normales  quizásí bueno pasa alguna vez (112.92-5.01)\n",
      "\n",
      "\n",
      "pero lo más normal es que te salve o que al menos te te acerque al al sitio que que pretendesir (117.93-7.26)\n",
      "\n",
      "\n",
      "y bueno la verdad el yo el único malo es que desde que saco fotografías conel (125.19-5.01)\n",
      "\n",
      "\n",
      "elefono no imprimo ni siquiera una y a veces siempre digo baa tengo que hacer una lista en el orde (130.20-5.01)\n",
      "\n",
      "\n",
      "nador de fotos que quiero imprimir para luego ponerlo en marcos pero nos vobvemos tan digitales que al final nos conformamos contenerlo o en el ordenador (135.21-7.77)\n",
      "\n",
      "\n",
      "o en el telefono móvil entonces es verdad que a veces si que toqu recordarme a mimis (142.98-5.01)\n",
      "\n",
      "\n",
      "sma que está muy bien todo lo tecnológico pero que (147.99-5.01)\n",
      "\n",
      "\n",
      "bería esforzar un poco más en estas cosas (153.00-2.61)\n",
      "\n",
      "\n",
      "que antiguamente cuando sacabas una foto eu mira  qué cosa más bonia (155.61-5.01)\n",
      "\n",
      "\n",
      "y sacabos una foto porque esa foto tenía un precio tenías que usar el carrete tenías que apuntar bien (160.62-5.28)\n",
      "\n",
      "\n",
      "y aparte no sabías como quedaba la foto hasta que no la revelaba i la veías (166.38-4.59)\n",
      "\n",
      "\n",
      "ahora va foto foto foto-foto  cuatrocientas mil fotos en el móvil (171.15-4.92)\n",
      "\n",
      "\n",
      "y nonoha perdido sentimientos de mala fotografía (176.76-5.01)\n",
      "\n",
      "\n",
      "como en otras aplicaciones móviles ha ganado veruno en calidad (181.77-5.01)\n",
      "\n",
      "\n",
      "bida porque te descargas un traductor de idiomas (186.78-3.54)\n",
      "\n",
      "\n",
      "y hablas con cualquier persona que te encuentres da iguale si tondesea porque le hablas (190.53-5.01)\n",
      "\n",
      "\n",
      "l móvilite traduce lo que estás diciendo y puede después por lo menos comunicarte con otra persona y saber (195.54-5.01)\n",
      "\n",
      "\n",
      "casi aciencia cierta que es lo que te está diciónsí  porque al fin acabo cuando nos vamos a otro país de (200.70-5.01)\n",
      "\n",
      "\n",
      "de vacaciones antes además de llevarte la guía tremenda con los mapas (205.71-5.01)\n",
      "\n",
      "\n",
      "los sitios que puedes visitar eh un diccionario paralo (210.72-5.01)\n",
      "\n",
      "\n",
      "obásico convers exactamente pero ahora llevas un telefono móvil y lo lleva lo llevar todo (215.73-6.03)\n",
      "\n",
      "\n",
      "y además todos los países tienen güífico lo cual puedes conectar cualquiereh (221.97-5.01)\n",
      "\n",
      "\n",
      "cualquier dispositivo y conseguir cualquier producto digital que que necesites (227.10-4.95)\n",
      "\n",
      "\n",
      "en yo de hecho me descargué alguna guía de viajes y el tener el libro digital descargado (233.31-5.01)\n",
      "\n",
      "\n",
      "eh en cualquier dispositivo electrónico a mí me ha salvado de (238.53-5.01)\n",
      "\n",
      "\n",
      "pues de perderme muchas ocasiones o de tener kir cargando con una cosa más  porque ahora conno (243.54-5.01)\n",
      "\n",
      "\n",
      "de que para que el precio de avión te salga barato el billete no puedes llevar mucho (248.55-5.01)\n",
      "\n",
      "\n",
      "equipaje pues todo lo que pueda ahorrar espacio y está claro que los froductos digitales nos ahorran muchísimo espacio (253.56-6.48)\n",
      "\n",
      "\n",
      "se hombre está claro (260.91-1.77)\n",
      "\n",
      "\n",
      "partev (262.95-1.95)\n",
      "\n",
      "\n",
      "vas de viaje entren y te descargas un par de películas para ver en el móvil lo en la table ya llevas el entretenimiento asegurado (264.90-7.47)\n",
      "\n",
      "\n",
      "lantesyas de viaje en a autobús y estaba el video estropeado y tetrabas igual cuatro cinco horas  en un autobúsy (273.42-7.14)\n",
      "\n",
      "\n",
      "escuchandol sonido las ruidas de las ruedas contra las falte (280.68-3.81)\n",
      "\n",
      "\n",
      "todo lo entretenimiento que dabía tambíén es verdad que a mí por ejemplo me encanta y recono (284.49-5.01)\n",
      "\n",
      "\n",
      "zco que tanto en casa como por la calle o a donde vaya e el descargarme plataformas digitales pero de música (289.50-6.90)\n",
      "\n",
      "\n",
      "h me gustan mucho porque además al final se acaban adaptando a tus gustos o puedes hacer como carpetas de diferentes estilos de de música (296.85-7.29)\n",
      "\n",
      "\n",
      "es verdad que hay muchas de pago pero bueno  también puedes tener la parte gratut (304.14-5.01)\n",
      "\n",
      "\n",
      "ita que hombre tiene alguna limitación pero te permite disfrutar igualmente de (309.15-5.01)\n",
      "\n",
      "\n",
      "de la música y yo para mis de las cosas más importantes  porque no salgo de ca (314.88-5.01)\n",
      "\n",
      "\n",
      "asa sin eh tener en el móvil mi plataforma de música y me encanta escucharla a donde vaya (319.89-5.40)\n",
      "\n",
      "\n",
      "también  sin embargo gracioso porque mago las listas de reproducción una aplicación totalmente gratuita (326.28-6.06)\n",
      "\n",
      "\n",
      "que sí que cada dos canciones  me sale publicidad (332.52-2.94)\n",
      "\n",
      "\n",
      "pero me deja la ventaja completa de hacer la lista de reproducción tal cual yo la quiero  porque despuesen esas listas aleatorias que aunque se aproximen a tus gusto sotal lo que me he encontrado (335.79-8.85)\n",
      "\n",
      "\n",
      "es que me se repiten las canciones cuatrocientas mil veces  entonces pues (345.21-4.53)\n",
      "\n",
      "\n",
      "lo que me agustado ha sido el otro que sí te da más trabajo que va seleccionando canción por canción y efectuando tu propielista pero (350.07-6.66)\n",
      "\n",
      "\n",
      "llevas diferentes listas para diferentes estados de ánimos y lo del libro  porque yo (357.81-5.01)\n",
      "\n",
      "\n",
      "sí que me he descargado un montón de de libros en en la table no y me resulta útil pues porque voy en el autobús y puedo ir leyendo (362.82-8.76)\n",
      "\n",
      "\n",
      "a donde vaya no  pero sin embargo eh también tengo amigos quee (371.58-5.01)\n",
      "\n",
      "\n",
      "han descargado mucho lo de los audiolibros pero amí sin embargo igual que la música me encanta (376.59-5.01)\n",
      "\n",
      "\n",
      "si me pongo el libro en audio la verdad es que me pierdo la mayoría de las cosas  porque me distraen (381.75-5.01)\n",
      "\n",
      "\n",
      "pues cualquier cosa que este pasando en la calle y a díte pasa o oyo llevas bienlo del fondome pasa porque yo libro me gusta leerlo  yo en mi propia cabeza le pongo las voces a cada personaje mi imaginadoel escenario  me imagino (387.24-13.38)\n",
      "\n",
      "\n",
      "todas las cosas que desarrollan la trama de una forma totalmente diferente y se me los tan (400.68-5.01)\n",
      "\n",
      "\n",
      "n relatando se me lo estan ahí acontando a la oreja (405.69-5.01)\n",
      "\n",
      "\n",
      "ame centro daparte no no me gusta no no lo disfruto  así como hay otro agente (410.70-5.01)\n",
      "\n",
      "\n",
      "e si lo disfrutará todo peísa lo panesta yo es que no no lo disfruto so me vuelve nmo (415.71-5.01)\n",
      "\n",
      "\n",
      "notono llega a burrirme incluso me puedo questar dormido  escuchándolo  yaigualcon (420.72-5.01)\n",
      "\n",
      "\n",
      "trar insomnio así es diba a decir que igual una noche que no pedas dormir te puedes conectar alaudiol (425.73-5.01)\n",
      "\n",
      "\n",
      "libro y pues mira eh no necesitas nada externo al airoso (430.74-5.01)\n",
      "\n",
      "\n",
      "uiero descargarme una (435.75-3.21)\n",
      "\n",
      "\n",
      "eh una canción no un audio de de una buena tormenta así con sus buenos truenos y la lluvia italia y me durmo más augusto queoco (439.77-8.67)\n",
      "\n",
      "\n",
      "adiolibrola uvide urugela estatengo pesadillas con la voz de la persona que los dares verdad (448.44-5.01)\n",
      "\n",
      "\n",
      "é ahora hasta pues con estas plataformas  tienes incluso eso (453.45-5.01)\n",
      "\n",
      "\n",
      "idos de ambiente (458.46-1.35)\n",
      "\n",
      "\n",
      "eh así que la verdad ca está hecho para todos los para todos los gustos yo por ejemplo (459.81-5.01)\n",
      "\n",
      "\n",
      "lgo que sí que me parece un adelanto total es tanto los tutoriales que te puedesen (464.82-5.01)\n",
      "\n",
      "\n",
      "ncontrar etutoriales de absolutamente todo y tiene su parte buen en su part (469.83-5.01)\n",
      "\n",
      "\n",
      "ade mala  porque ahora de repente toormundo secre profesional gonver un tutoreal pero es verdad que para cosas sencillas (474.84-5.07)\n",
      "\n",
      "\n",
      "es yo creo que es muy práctico e nos hace ahorrar tiempo (479.91-5.01)\n",
      "\n",
      "\n",
      "que necesito saber como arreglar esto como ver esto o como funciona esto en el ordenador o en mitablet y simplemente (484.92-8.31)\n",
      "\n",
      "\n",
      "tecleas lo que necesitas buscar y se te habre en un montón de de tutoriales que a lo mejores de cinco minutos y y te ahorra mucho tiempo y esfuerzo (493.23-8.19)\n",
      "\n",
      "\n",
      "eso de los tutoriales y que me damos la atención de ver alguno porque aver  mí siempre me gustó trabajar con las manos y dese que tengo uso de razón (501.72-8.22)\n",
      "\n",
      "\n",
      "como callera de el mis manus un destornillador ya le aligabay ahoracha (509.94-5.01)\n",
      "\n",
      "\n",
      "nsentido figurado no que hay hasta tutoriales de cómo utilizar un destormillador (515.31-5.01)\n",
      "\n",
      "\n",
      "como utilizar un martillo tales como perobamos a verse hemos llegado tal punto de de vagancia neuronal (520.32-6.84)\n",
      "\n",
      "\n",
      "que prefiero ver un tutoreal de como utilizar un destornidador en vez de coger el destorneador y probar haber como funcional (527.52-5.16)\n",
      "\n",
      "\n",
      "que tampoco es tan difícil es más sencillo que el mecanismo de un chuquetepero (533.28-5.01)\n",
      "\n",
      "\n",
      "emos llegado aplicaciones ya para para todos yo creo que si te pones a buscar (538.29-5.25)\n",
      "\n",
      "\n",
      "e una aplicación de cómo descargar aplicaciones tonces ya es graciosono (544.17-5.01)\n",
      "\n",
      "\n",
      "nos han mejorado mucho la vida todoel tema de aplicaciones y productos digitales (549.18-6.15)\n",
      "\n",
      "\n",
      "pero a la vez yo creo que nos han vuelto un poquito tontos también porque ya nos hemos acostumbrado depender tanto de toda (555.81-6.33)\n",
      "\n",
      "\n",
      "de toda esta interactividad electrónica que tenemos n nuestros telefonos estables televisiones inteligentes y demás (562.38-6.51)\n",
      "\n",
      "\n",
      "que ya ese nos están atrofeando las neuronas porque idea llega un momento en que (569.70-4.32)\n",
      "\n",
      "\n",
      "ya no sabemos nui como comunicarnos  a veces con otros seres humanos (574.11-5.01)\n",
      "\n",
      "\n",
      "si noes aradesde mensajes porque que ya no hablamos ya no escribimos mensajes ni como hablamos (579.12-5.70)\n",
      "\n",
      "\n",
      "porque utilizamos tanta abreviatura y tanto psemóticonoso (584.82-5.01)\n",
      "\n",
      "\n",
      "e tal que es que ya yo creo que hay gente que está perdiendo la capacidad de de comunicarse atraso (589.83-5.01)\n",
      "\n",
      "\n",
      "hblapuede ser lo que si es verdad es que todos los productos digitales al fin acabo están (594.84-5.01)\n",
      "\n",
      "\n",
      "n hechos para que las personas cada día vivan más cómodas y y que todo sea más fáci (599.85-5.01)\n",
      "\n",
      "\n",
      "el tamino es verdad que yo he visto según quetutoriales o lecciones educativas (605.07-5.01)\n",
      "\n",
      "\n",
      "elo cierto es que si es muy útil y hay muchas personas que lo ven (610.08-5.07)\n",
      "\n",
      "\n",
      "ah pues al final ellos pueden llegar a tener ingresos  gracias a eso no y es verdad quem (615.15-5.01)\n",
      "\n",
      "\n",
      "parece util imporce justo que haya gente que vaya a recibir dinero uepor su conocimiento (620.16-7.02)\n",
      "\n",
      "\n",
      "y que y quel resto de personas pues nos podamos beneficiar de ellode hecho (627.18-5.31)\n",
      "\n",
      "\n",
      "pues a mí por ejemplo me gusta mucho el italiano pero no tengo tiempo de ir a clases o comoon (632.55-5.01)\n",
      "\n",
      "\n",
      "hobby pues a lo mejor no tengo ingresos muy altos y buenos postería (637.56-5.01)\n",
      "\n",
      "\n",
      "a un dinero que me costaría un poco utilizar para eso no y gracias a estas plataformas y demás (642.57-6.60)\n",
      "\n",
      "\n",
      "pues tienes cursos desde nivel cero para aprender italiano oybueno laverdad q (649.35-7.41)\n",
      "\n",
      "\n",
      "aver no es que lo hablen y mucho menos pero al menos como hobby  me resulta práctico y hay un montón de (656.91-5.97)\n",
      "\n",
      "\n",
      "de clases de italiano gratis franceschi no la verdaes que lo tienes todo (663.12-3.99)\n",
      "\n",
      "\n",
      "chis la verdad que sí (667.80-1.83)\n",
      "\n",
      "\n",
      "mi lo que me gusta ver últimamente yamás me resulta muy relajante (669.87-4.53)\n",
      "\n",
      "\n",
      "son páginas donde hay artistas queaisa (674.55-5.01)\n",
      "\n",
      "\n",
      "sus cuadros y sus obras en directo y ves como como los hacen yspues nunca me hubiera imaginado queda mejor un cuadro astrap (679.56-7.59)\n",
      "\n",
      "\n",
      "de colores vivos y llamativos  eh pues nunca m (687.15-5.01)\n",
      "\n",
      "\n",
      "yhubiere imaginado como los hacen en realidad porque no lo ve hecho y dichermanemea pues paesa (692.16-5.01)\n",
      "\n",
      "\n",
      "mezcla colores y tal y cuando de repente vez como es latecnica que utilizan e tal crus (697.17-4.35)\n",
      "\n",
      "\n",
      "te quedas asombrado  no aprendes  aprendes cosas  la verdad que yo si es (701.52-5.01)\n",
      "\n",
      "\n",
      "es útil y es bonito es entretenido y si la gente llega a cobrar (706.53-5.01)\n",
      "\n",
      "\n",
      "r por esa por esos videos que está haciendo  porque están colaborando con el aprende (711.54-5.01)\n",
      "\n",
      "\n",
      "izaje de otras personas y demás pues es estupendo porque se veen recompensados por sues fuerzoo (716.55-5.01)\n",
      "\n",
      "\n",
      "por su lador (721.56-1.02)\n",
      "\n",
      "\n",
      "es verdad  además no sé la horae que con ayuda de de internepues ahora (723.15-5.01)\n",
      "\n",
      "\n",
      "tienes un montón de manuales y de guías yo por ejemplo el otro día compramos un robod de cocina (728.16-5.25)\n",
      "\n",
      "\n",
      "y me llamó monto la atención por cara todo vien conectado alagui fino yntovestin (733.62-5.01)\n",
      "\n",
      "\n",
      "ene como una pantallita pequeña y te viene tanto el manual de usuario que hasta ya directamente aceptasto (738.63-5.01)\n",
      "\n",
      "\n",
      "aí eh y pertevinen las recetas paso a paso porque viene conectado internet y tiene saituhumano (743.64-5.01)\n",
      "\n",
      "\n",
      "al de cocina no y ponerse cualquier receta tarta de zanahoria (748.65-5.01)\n",
      "\n",
      "\n",
      "dice los ingredientes debaiciendo paso a paso ahora pon esto a tanta velocidad a tanto tiempo (753.66-5.07)\n",
      "\n",
      "\n",
      "y bueno  la verdad que para la gente que no tenemos tiempo de cocinar  o que nos cuesta (759.06-5.01)\n",
      "\n",
      "\n",
      "decir quiero hacer un plato rico pero no me apetecechar toda la tarde en la cocina a ponerme a buscar una receta el hecho es simplemente encender una máquina (764.07-7.38)\n",
      "\n",
      "\n",
      "es coger una receta y que te venga star con imágenes  para mi es eres un adelanto (771.60-5.01)\n",
      "\n",
      "\n",
      "h  total  la verdades que me gusta mucho (776.61-2.61)\n",
      "\n",
      "\n",
      "ye hay cosas en las que  igual que el rogotaspirador ya que te destaesta cuando se tecays una amiga en el suelo y ya va quevamoso (779.43-6.72)\n",
      "\n",
      "\n",
      "te lo deja limpio (786.21-2.88)\n",
      "\n",
      "\n",
      "barrido y casi quefregado a a la vez no son cosas que ste soluion (789.15-5.01)\n",
      "\n",
      "\n",
      "nan la vida (794.16-1.68)\n",
      "\n",
      "\n",
      "es es curioso que no hace tantos años todos los mecanismos que había (796.17-5.01)\n",
      "\n",
      "\n",
      "e para l le iempiezad a una casara nascobón recogió drun cubo unafregona (801.18-3.69)\n",
      "\n",
      "\n",
      "y corre y ahora pues yatienes electrónica  tienes uno (804.87-5.01)\n",
      "\n",
      "\n",
      "s aspiradores inteligentes que detectan el grado de suciedad que tienen (809.88-5.01)\n",
      "\n",
      "\n",
      "en el suelo y se ajustan con baterías recargablesno esque he hecho tema (814.89-5.01)\n",
      "\n",
      "\n",
      "e desela del wibi yaumalmapa impecable porque no chocan contronado (819.90-5.01)\n",
      "\n",
      "\n",
      "an detectando y (824.91-1.80)\n",
      "\n",
      "\n",
      "esquinitas curvas y jarrones cosas delicadas  lo detectan no rompen nada a lo esquivo (826.71-5.19)\n",
      "\n",
      "\n",
      "la verdad que oyes  llamativo pero a la vez también te hace pensar no (832.53-5.01)\n",
      "\n",
      "\n",
      "e tanta con estívidad tanta conectividad llegaun momento en que (837.54-3.39)\n",
      "\n",
      "\n",
      "estás completamente saturao por todos lados  porque todo esotro (841.23-5.01)\n",
      "\n",
      "\n",
      "ming emplica después las publicidades que te cuelan por todos sitios (846.24-3.84)\n",
      "\n",
      "\n",
      "y cómo van adaptadas a lo que tu tienes en casa noes la publicidad tanpero (850.26-5.01)\n",
      "\n",
      "\n",
      "sonalizada (855.27-1.26)\n",
      "\n",
      "\n",
      "que es que ya no te das ni cuenta de de cómo te están controlando con todo eso (856.80-5.01)\n",
      "\n",
      "\n",
      "tú haces cualquier búsqueda por googl (861.81-2.82)\n",
      "\n",
      "\n",
      "y al ratítulo que te sale ya es un montón de publicidad relacionada con las búsquedas o sapones un nombre de un grupo de música (865.44-6.24)\n",
      "\n",
      "\n",
      "en una aplicación de música y a los dos meses  siguen saliendo listas de reproduco (872.40-5.01)\n",
      "\n",
      "\n",
      "ción con esos grupos de de música (877.41-2.58)\n",
      "\n",
      "\n",
      "laspecto en el que se quedan guardadas todas tus interacciones digitales (879.99-5.01)\n",
      "\n",
      "\n",
      "para después solucionarte las búsquedas de una forma mucho  más rápido (885.00-5.01)\n",
      "\n",
      "\n",
      "stres letras y ya te aparece la palabra que estar buscando si está claro que todo lo digital está hecho (890.01-5.01)\n",
      "\n",
      "\n",
      "ara facilitarnos la vida y por supuesto también tiene su uso (895.02-3.57)\n",
      "\n",
      "\n",
      "iene sus contras desde luego yo todas las personas que conozco que tienen pues por ejemplo eso los aspiradores (898.59-5.01)\n",
      "\n",
      "\n",
      "robot los inteligentes bueno no lo cambiarían por nada porque sobre tebas de casa y cuando vuel (903.60-5.01)\n",
      "\n",
      "\n",
      "lves tienes tu casa limpia el robot de cocina eh te pones a cocinar y sacas una rece (908.61-5.01)\n",
      "\n",
      "\n",
      "taque de otra manera no seríaes capaz de de hacer ehbueno (913.62-5.01)\n",
      "\n",
      "\n",
      "es que ahora hasta las cosas del pelo casi vienen con con wifino entonces verdad que a veces es un poco exagerado pero (918.63-8.07)\n",
      "\n",
      "\n",
      "yo creo que la mayoría de personas que haya hemos conseguido esas cosas a día de hoy no renunciaríamos a ella (926.70-6.21)\n",
      "\n",
      "\n",
      "uh por ejemplo e ahora es verdad que muchas reuniones de trabajoclases (933.27-5.01)\n",
      "\n",
      "\n",
      "online todo lo hacemos por plataformasehhaces una videollamada eilo (938.28-5.01)\n",
      "\n",
      "\n",
      "que antes para una empresa era si la empresa está en madrid y yo vivo en galicia  por ejemlo (943.29-5.76)\n",
      "\n",
      "\n",
      "pues era comprar el billete y da y vuelta el tiempo demás que tiene que echar el empleado en desplazamientos el dinero que suele cuesta la empresa a día de hoy es (949.05-9.51)\n",
      "\n",
      "\n",
      "tengo un dispositivo electrónico e puedo asistir a una reunión de trabajo en cualquier parte del mundo y (958.65-6.57)\n",
      "\n",
      "\n",
      "claro los beneficios para mí son increíbles porque no dependes (965.28-5.01)\n",
      "\n",
      "\n",
      "es verdad que no es lo mismo envidio conferencia que en persona pero también los beneficios a mi modo (970.32-5.01)\n",
      "\n",
      "\n",
      "o de ver son muchísimos (975.33-2.10)\n",
      "\n",
      "\n",
      "la verdad que sísobre todo a la hora de de llegar a tiempo a una reunión en (977.58-6.42)\n",
      "\n",
      "\n",
      "tema importante y trascendental  pues ya no te preocupas de de unque estar en otra parte del mundo en seis horas (984.15-7.02)\n",
      "\n",
      "\n",
      "no eh (991.20-1.86)\n",
      "\n",
      "\n",
      "e elimina muchos  trescon esta sala hora prevista la ora programada y ninguna de las partes está esperando a que surcon imprevisto qu l otra persona no se puede conecter (993.06-8.46)\n",
      "\n",
      "\n",
      "entonces eso la verdad que tieneunos beneficios enormes (1002.24-4.71)\n",
      "\n",
      "\n",
      "sobre todo también en la calidad de de vida familiar que gana uno porque nos lo misomostar o (1006.95-5.01)\n",
      "\n",
      "\n",
      "vida viajando para reunirte con un cliente en un sitio  cliente en otro (1011.96-4.35)\n",
      "\n",
      "\n",
      "si ahora lo puede hacer atras debido a conferencias h (1016.31-2.94)\n",
      "\n",
      "\n",
      "la calidad de vida mejorado pero muchísimo y eso engran partes gracias a todos estos (1019.70-5.76)\n",
      "\n",
      "\n",
      "productos digitales que tenemos hoy en día sí porque mira ya no solo a nivel empresa en el momento enque tu (1025.46-5.01)\n",
      "\n",
      "\n",
      "ives en una ciudad diferente a la que vive (1030.47-2.70)\n",
      "\n",
      "\n",
      "tu familia y pues a lo mejor tienes vacaciones una vez al año eh bueno ues (1033.17-5.01)\n",
      "\n",
      "\n",
      "lo veías lo justo ahora día de hoy simplemente con telefonio móvileh (1038.18-5.13)\n",
      "\n",
      "\n",
      "cualquiera pepe te permite hacer video llamada y poder no solo escucharles sino también verles y yo creo que es algo que no (1043.43-7.80)\n",
      "\n",
      "\n",
      "algo que no tiene precio porque hay muchas familias que cada uno vive en un lado del mundo (1051.44-5.01)\n",
      "\n",
      "\n",
      "y poder ver tanto a tus padres como a bebes nuevos que nacen en la familia  yo creo que es algo muy muy bonito (1056.45-6.45)\n",
      "\n",
      "\n",
      "sí es la verdad que sís (1063.59-1.77)\n",
      "\n",
      "\n",
      "está claro que ahora mismo el que no se mantienen contacto con sus familiares y sus seres queridos es porque no quiere nopor (1066.05-6.00)\n",
      "\n",
      "\n",
      "no porque no tenga posibilidad de como hacerlo (1072.05-3.54)\n",
      "\n",
      "\n",
      "s es así cualquier evento que pasa que no puede unavido conferen (1076.19-5.01)\n",
      "\n",
      "\n",
      "encia porque hoy igual por horarios depende del sitio mononel qu estás viviendo pero grabas onbíreo (1081.20-5.01)\n",
      "\n",
      "\n",
      "te sacaso nas fóto las puedes enviar con a con na frase dedicada a ese familiar (1086.21-5.01)\n",
      "\n",
      "\n",
      "n concreto sea que la verdad que (1091.22-2.22)\n",
      "\n",
      "\n",
      "que sí yues así una de las cosas que más me gustan a mí  por m (1093.71-5.01)\n",
      "\n",
      "\n",
      "mploes el tener alta voces bluetu chatemueves por toda la casa con el telefono en alvol (1098.72-5.01)\n",
      "\n",
      "\n",
      "cho lo ibas escuchando a la música y donde esté simpreocuparte de lo largo que es el cableq (1103.73-5.01)\n",
      "\n",
      "\n",
      "y que me queda ota que no puedo llevarme ulos paquí porque no tengo panchufarlo (1108.74-4.08)\n",
      "\n",
      "\n",
      "chufar los salta voces en la sala y estás cocinado en la cocina estar escuchando la música igual (1112.91-5.01)\n",
      "\n",
      "\n",
      "a verad esca al final yo creo que todos son que todos son adelantos y ahora es que parece que empedirnos de comprar (1117.92-5.01)\n",
      "\n",
      "\n",
      "saun centro comercial abrimos el appestor ytenemos (1122.93-5.01)\n",
      "\n",
      "\n",
      "para elegir un mundo de cosas tanto se a para educación (1127.94-5.01)\n",
      "\n",
      "\n",
      "omo para entretenimiento cosas prácticas para el trabajo hay un abanico que (1132.95-5.01)\n",
      "\n",
      "\n",
      "reo que no somos ni capaces de de llegar a entender del todo pero hay para todotipo (1137.96-5.01)\n",
      "\n",
      "\n",
      "naamás yaes que no tienes que salir de casa si no quieres hasta para hacer la compra pero la compra (1142.97-5.01)\n",
      "\n",
      "\n",
      "tiwallen en el centro comercial más exclusivo (1147.98-5.01)\n",
      "\n",
      "\n",
      "en la tienda de renombre tiene sucursales entol (1152.99-5.01)\n",
      "\n",
      "\n",
      "o en la tienda de de paquitoel quiosquero de la esquina que casi que tiene ya su tienta unline también qe (1159.17-6.42)\n",
      "\n",
      "\n",
      "hoy en día como si haces la compra por internet y entras por una parca (1166.28-5.01)\n",
      "\n",
      "\n",
      "iento a recogerla directamente casi no tienes ni que bajar del coche para para recoger tu compra (1171.29-4.65)\n",
      "\n",
      "\n",
      "yo creo que el próximo producto digital que voy a tener va a ser e un altavoz inteligente (1176.12-5.01)\n",
      "\n",
      "\n",
      "de esto que tu le hablas y ella a obedece lo que lo que le dices me parece super práctico  la verdad e verdad qu (1181.37-7.47)\n",
      "\n",
      "\n",
      "me puedo hacer un poco vaga pero me parece un adelanto total  creo que (1189.32-5.01)\n",
      "\n",
      "\n",
      "que viva solo tienes alingún quien hablachllegas a casa y le dice (1194.33-5.01)\n",
      "\n",
      "\n",
      "las persianas terramó las ventanas era condiciona al temperaturaexactate (1199.34-5.01)\n",
      "\n",
      "\n",
      "bueno vivila época de los productos digitales también tiene sus benefice (1204.38-5.01)\n",
      "\n",
      "\n",
      "cinos pal (1209.39-0.96)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#define input\n",
    "audioFile = '/home/asrivast/d/Data/Speech/MagicData/Spanish_Conversational_Speech_Test_Corpus/WAV/A0001_S003_0_G0001_G0002.wav'\n",
    "SttModelFolder = \"/home/asrivast/Models/wav2vec2-large-xlsr-53-spanish/\"\n",
    "outFolder='/tmp'\n",
    "sampleRate = 16000\n",
    "useGPUifAvailable = True\n",
    "useLM = False\n",
    "\n",
    "##define constants\n",
    "aggressiveness = 3\n",
    "frameDurationMs = 30\n",
    "numFramesInWindow = 20\n",
    "\n",
    "## initialize segmenter\n",
    "print('Initializing Audio Segmenter with aggressiveness=%d frame length=%dmsec window size=%dframes and sample rate=%d\\n'\n",
    "     % (aggressiveness, frameDurationMs, numFramesInWindow, sampleRate))\n",
    "segmenter = AudioSegmenter(aggressiveness, frameDurationMs, numFramesInWindow, sampleRate, 2)\n",
    "\n",
    "## initialize STT model including LM if required\n",
    "device = \"cuda\" if (useGPUifAvailable and torch.cuda.is_available()) else \"cpu\"\n",
    "print('device = %s' % device)\n",
    "print('Loading speech recognition model from folder %s\\n' % SttModelFolder)\n",
    "model = SpeechRecognitionModel2(SttModelFolder, device=device)\n",
    "decoder = None\n",
    "if useLM == True:\n",
    "    from huggingsound import ParlanceLMDecoder\n",
    "    LmModelFolder = SttModelFolder + \"/language_model/\"\n",
    "    lm_path = LmModelFolder + \"lm.binary\"\n",
    "    unigrams_path = LmModelFolder + \"unigrams.txt\"\n",
    "    # To use this decoder you'll need to install the Parlance's ctcdecode first (https://github.com/parlance/ctcdecode)\n",
    "    print('Starting to load LM file %s in ParlanceLMDecoder ...' % lm_path)\n",
    "    decoder = ParlanceLMDecoder(model.token_set, lm_path=lm_path, alpha=2, beta=1, beam_width=100)    \n",
    "    #decoder = KenshoLMDecoder(model.token_set, lm_path=lm_path, unigrams_path=unigrams_path, alpha=2, beta=1, beam_width=100)\n",
    "    print(\"Finished loading Language Model\")\n",
    "\n",
    "#read audio file into buffer\n",
    "audio, sample_rate = read_wave(audioFile)\n",
    "assert sample_rate == sampleRate\n",
    "\n",
    "sessionId = os.path.basename(audioFile).split('.')[0]\n",
    "print('%s %d %.2f %s\\n' % (sessionId, sample_rate, (len(audio)/(sample_rate * 2)), audioFile))\n",
    "\n",
    "segments = segmenter.process(audio, 0.75, 5, frameDurationMs/1000)\n",
    "\n",
    "transcripts = model.transcribeAudio(segments, 1, decoder)\n",
    "#transcripts = model.transcribeAudio(segments[2:4], 1, decoder)\n",
    "#print(transcripts)\n",
    "\n",
    "with open(('/tmp/%s.ctm' % sessionId), 'w') as ofp:\n",
    "    for transcript in transcripts:\n",
    "        print('\\n%s (%s-%s)\\n' % (transcript['transcription'], transcript['utterance_start'], transcript['utterance_duration']))\n",
    "        for token in transcript[\"tokens\"]:\n",
    "            ofp.write(\"%s \\t 1 \\t %.2f \\t %.2f \\t %s\\n\" % (sessionId, token[\"start\"], token[\"duration\"], token[\"baseform\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494f78a",
   "metadata": {},
   "source": [
    "## This block can save audio for each segment into files and run decoder on individual files to compare to the previous block \n",
    "from traceback import print_tb\n",
    "import torch\n",
    "import os.path\n",
    "import argparse\n",
    "from huggingsound import SpeechRecognitionModel, KenshoLMDecoder\n",
    "\n",
    "outFolder = '/tmp/'\n",
    "device = \"cuda\" if (torch.cuda.is_available()) else \"cpu\"\n",
    "SttModelFolder = \"/Users/asrivast/Models/wav2vec2-large-xlsr-53-english/\"\n",
    "model = SpeechRecognitionModel2(SttModelFolder, device=device)\n",
    "print(model.processor.feature_extractor.sampling_rate)\n",
    "useLM = False\n",
    "decoder = None\n",
    "if useLM == True:\n",
    "  LmModelFolder = SttModelFolder + \"/language_model/\"\n",
    "  lm_path = LmModelFolder + \"lm.binary\"\n",
    "  unigrams_path = LmModelFolder + \"unigrams.txt\"\n",
    "  decoder = KenshoLMDecoder(model.token_set, lm_path=lm_path, unigrams_path=unigrams_path, alpha=2, beta=1, beam_width=100)\n",
    "  print(\"Finished loading Language Model\")\n",
    "\n",
    "audioFilesList = []\n",
    "for i, segment in enumerate(segments):\n",
    "    path = outFolder\n",
    "    path = path + ('chunk-%002d.wav' % (i,)) \n",
    "    print('\\nWriting %s %.2f %.2f %d\\n' % (path, segment.timestamp, segment.duration, len(segment.audio)))\n",
    "    write_wave(path, segment.bytes, sample_rate)\n",
    "    audioFilesList.append(path)\n",
    "\n",
    "transcripts = model.transcribeFiles(audioFilesList, 1, decoder)\n",
    "#print(transcripts)\n",
    "#audioFilesList.clear()\n",
    "\n",
    "\n",
    "for transcript in transcripts:\n",
    "    print('%s\\n' % (transcript['transcription']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1478e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
